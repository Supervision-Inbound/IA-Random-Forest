name: IA Forecast + Alertas

on:
  workflow_dispatch:
  # Si luego quieres que corra solo, descomenta:
  # schedule:
  #   - cron: "0 6 * * *"   # todos los días 06:00 UTC

permissions:
  contents: write

jobs:
  run:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'
          cache: 'pip'            # ✅ acelera corridas siguientes

      - name: Install deps
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt

      - name: Install unzip & jq
        run: sudo apt-get update && sudo apt-get install -y unzip jq

      # ====== MODELOS ======
      - name: Download models.zip from latest Release
        env:
          GH_TOKEN: ${{ github.token }}
        run: |
          mkdir -p models
          API="https://api.github.com/repos/${GITHUB_REPOSITORY}/releases/latest"
          ASSET_URL=$(curl -s -H "Authorization: Bearer ${GH_TOKEN}" "$API" \
            | jq -r '.assets[] | select(.name=="models.zip") | .url')
          if [ -z "$ASSET_URL" ]; then
            echo "models.zip no encontrado en el último release"; exit 1
          fi
          curl -L -H "Authorization: Bearer ${GH_TOKEN}" \
               -H "Accept: application/octet-stream" \
               "$ASSET_URL" -o models.zip
          unzip -o models.zip -d models
          echo "PKLs en models/"; find models -maxdepth 3 -type f -name "*.pkl" -ls

      # ====== DATASET PARQUET ======
      - name: Download dataset (parquet) from latest Release
        env:
          GH_TOKEN: ${{ github.token }}
        run: |
          mkdir -p data
          API="https://api.github.com/repos/${GITHUB_REPOSITORY}/releases/latest"
          DATA_URL=$(curl -s -H "Authorization: Bearer ${GH_TOKEN}" "$API" \
            | jq -r '.assets[] | select(.name=="dataset_entrenamiento_llamadas.parquet") | .url')
          if [ -z "$DATA_URL" ]; then
            echo "dataset_entrenamiento_llamadas.parquet no encontrado en el último release"; exit 1
          fi
          curl -L -H "Authorization: Bearer ${GH_TOKEN}" \
               -H "Accept: application/octet-stream" \
               "$DATA_URL" -o data/dataset_entrenamiento_llamadas.parquet
          ls -lh data

      - name: Run pipeline
        env:
          # Fuentes externas (opcional)
          CLIMA_URL:     ${{ secrets.CLIMA_URL }}
          TURNOS_URL:    ${{ secrets.TURNOS_URL }}

          # Parámetros Erlang C (opcional; si no pones secretos, usa defaults del script)
          SLA_TARGET:    ${{ secrets.SLA_TARGET }}      # ej. 0.9
          ASA_SECONDS:   ${{ secrets.ASA_SECONDS }}     # ej. 20
          OCCUPANCY_MAX: ${{ secrets.OCCUPANCY_MAX }}   # ej. 0.85
          SHRINKAGE:     ${{ secrets.SHRINKAGE }}       # ej. 0.3

          # ⚡ Performance flags (puedes definirlas como Repository > Variables):
          FAST_GLOBAL:   ${{ vars.FAST_GLOBAL || '1' }}   # 1 = solo serie global (mucho más rápido)
          MAX_COMUNAS:   ${{ vars.MAX_COMUNAS || '20' }}  # límite de comunas si FAST_GLOBAL=0

          # Forzar que exista el parquet del release:
          REQUIRE_DATASET: "1"
        run: |
          date
          python run_pipeline.py
          date

      - name: Commit JSON outputs
        run: |
          git config user.name  "github-actions[bot]"
          git config user.email "github-actions[bot]@users.noreply.github.com"
          git add out/*.json || true
          git commit -m "chore: actualizar JSONs de forecast/alertas" || echo "Nada que commitear"
          git push

