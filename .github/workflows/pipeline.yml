name: IA Forecast + Alertas

on:
  workflow_dispatch:
  # schedule:
  #   - cron: "0 6 * * *"   # opcional: ejecutar diario 06:00 UTC

permissions:
  contents: write

jobs:
  run:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'
          cache: 'pip'       # ✅ acelera corridas siguientes

      - name: Install deps
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt

      - name: Install unzip & jq
        run: sudo apt-get update && sudo apt-get install -y unzip jq

      # ====== MODELOS ======
      - name: Download models.zip from latest Release
        env:
          GH_TOKEN: ${{ github.token }}
        run: |
          mkdir -p models
          API="https://api.github.com/repos/${GITHUB_REPOSITORY}/releases/latest"
          ASSET_URL=$(curl -s -H "Authorization: Bearer ${GH_TOKEN}" "$API" \
            | jq -r '.assets[] | select(.name=="models.zip") | .url')
          if [ -z "$ASSET_URL" ]; then
            echo "models.zip no encontrado en el último release"; exit 1
          fi
          curl -L -H "Authorization: Bearer ${GH_TOKEN}" \
               -H "Accept: application/octet-stream" \
               "$ASSET_URL" -o models.zip
          unzip -o models.zip -d models
          echo "PKLs en models/"; find models -maxdepth 3 -type f -name "*.pkl" -ls

      # ====== DATASET PARQUET ======
      - name: Download dataset (parquet) from latest Release
        env:
          GH_TOKEN: ${{ github.token }}
        run: |
          mkdir -p data
          API="https://api.github.com/repos/${GITHUB_REPOSITORY}/releases/latest"
          DATA_URL=$(curl -s -H "Authorization: Bearer ${GH_TOKEN}" "$API" \
            | jq -r '.assets[] | select(.name=="dataset_entrenamiento_llamadas.parquet") | .url')
          if [ -z "$DATA_URL" ]; then
            echo "dataset_entrenamiento_llamadas.parquet no encontrado en el último release"; exit 1
          fi
          curl -L -H "Authorization: Bearer ${GH_TOKEN}" \
               -H "Accept: application/octet-stream" \
               "$DATA_URL" -o data/dataset_entrenamiento_llamadas.parquet
          ls -lh data

      - name: Run pipeline
        env:
          # Fuentes externas (opcional)
          CLIMA_URL:     ${{ secrets.CLIMA_URL }}
          TURNOS_URL:    ${{ secrets.TURNOS_URL }}

          # Erlang C (opcional) – si no están, el script usa defaults
          SLA_TARGET:    ${{ secrets.SLA_TARGET }}
          ASA_SECONDS:   ${{ secrets.ASA_SECONDS }}
          OCCUPANCY_MAX: ${{ secrets.OCCUPANCY_MAX }}
          SHRINKAGE:     ${{ secrets.SHRINKAGE }}

          # ⚡ Performance y modo nacional:
          FAST_GLOBAL:   "1"      # 1 = solo serie global
          MAX_COMUNAS:   "20"     # límite si FAST_GLOBAL=0

          # Exigir parquet (si falta, el run falla – no hay fallback)
          REQUIRE_DATASET: "1"
        run: |
          echo "FAST_GLOBAL=${FAST_GLOBAL}  MAX_COMUNAS=${MAX_COMUNAS}"
          date
          python run_pipeline.py
          date

      - name: Inspect outputs
        run: |
          echo "SHA256 de salidas:"
          sha256sum out/forecast_mensual.json || true
          sha256sum out/alertas_climatologicas.json || true
          sha256sum out/alertas_turnos.json || true
          echo "--- HEAD forecast_mensual.json ---"
          head -n 20 out/forecast_mensual.json || true

      - name: Commit JSON outputs
        run: |
          git config user.name  "github-actions[bot]"
          git config user.email "github-actions[bot]@users.noreply.github.com"
          git add -A
          git commit -m "chore: actualizar JSONs de forecast/alertas" || echo "Nada que commitear"
          git push

